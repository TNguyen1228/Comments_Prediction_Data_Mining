{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import  DecisionTreeRegressor\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tuan Ngua\\AppData\\Local\\Temp\\ipykernel_1448\\3134575670.py:7: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  test=pd.read_csv(file_test, header=None)\n"
     ]
    }
   ],
   "source": [
    "#data train\n",
    "file_train='blogfeedback/train/blogData_train.csv'\n",
    "train=pd.read_csv(file_train, header=None)\n",
    "\n",
    "#data test\n",
    "file_test='blogfeedback/test/blogData_test.csv'\n",
    "test=pd.read_csv(file_test, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52397, 281), (7625, 281))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "# # Set the size and style of the plots\n",
    "# sns.set_theme(style=\"whitegrid\")\n",
    "# plt.figure(figsize=(15, 10))\n",
    "\n",
    "# # Define the feature indices based on the description\n",
    "# features = {\n",
    "#     \"Total comments before basetime (51)\": 50,\n",
    "#     \"Comments in last 24 hours (52)\": 51,\n",
    "#     \"Comments between T1 and T2 (53)\": 52,\n",
    "#     \"Comments in first 24 hours after publication (54)\": 53,\n",
    "#     \"Difference of Attribute 52 and 53 (55)\": 54,\n",
    "#     \"Target: Comments in next 24 hours (281)\": 280\n",
    "# }\n",
    "\n",
    "# # Create histograms and boxplots\n",
    "# fig, axes = plt.subplots(3, 2, figsize=(15, 15))\n",
    "# for ax, (label, index) in zip(axes.flatten(), features.items()):\n",
    "#     sns.histplot(train[index], bins=30, ax=ax, kde=False, color='skyblue')\n",
    "#     ax.set_title(label)\n",
    "#     ax.set_ylabel('Frequency')\n",
    "\n",
    "# # Tight layout for better spacing\n",
    "# plt.tight_layout()\n",
    "\n",
    "# # Display the figure\n",
    "# plt.show()\n",
    "\n",
    "# # Create scatter plots for relationships\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# for i, (label, index) in enumerate(features.items()):\n",
    "#     if \"Target\" not in label:\n",
    "#         plt.scatter(train[index], train[280], alpha=0.5, label=label)\n",
    "# plt.title('Scatter plot of features vs. Target (Comments in next 24 hours)')\n",
    "# plt.xlabel('Feature values')\n",
    "# plt.ylabel('Comments in next 24 hours')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(train.columns[:50], axis=1)  # Drop the first 50 columns\n",
    "test = test.drop(test.columns[:50], axis=1)  # Drop the first 50 columns\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (52397, 230)\n",
      "y_train shape: (52397,)\n",
      "X_test shape: (7625, 230)\n",
      "y_test shape: (7625,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to confirm\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class RandomForestRegressor():\n",
    "    \"\"\"Implement Random Forest regressor from scratch using Decision Tree.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        criterion='mse', \n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt', \n",
    "        min_impurity_decrease=0.0,\n",
    "        random_state=0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Some important parameters in Random Forest.\n",
    "        \n",
    "        Args:\n",
    "            n_estimators (int): The number of trees in the forest.\n",
    "            criterion (str): The function to measure the quality of a split ('mse' for mean squared error).\n",
    "            max_depth (int): The maximum depth of the tree.\n",
    "            min_samples_leaf (int): The minimum number of samples required to be at a leaf node.\n",
    "            max_features (str): The number of features to consider when looking for the best split; 'sqrt' for square root.\n",
    "            min_impurity_decrease (float): A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "            random_state (int): Controls randomness of the bootstrap samples and the features.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion =  criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the random forest model.\"\"\"\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        if self.max_features == 'sqrt':\n",
    "            self.max_feature = int(np.sqrt(self.n_features))\n",
    "        \n",
    "        self.trees = []\n",
    "        for i in range(self.n_estimators):\n",
    "            X_train, _, y_train, _ = train_test_split(\n",
    "                X, \n",
    "                y, \n",
    "                test_size=0.3, \n",
    "                random_state=self.random_state + i\n",
    "            )\n",
    "            tree = DecisionTreeRegressor(\n",
    "                criterion = self.criterion,\n",
    "                max_depth = self.max_depth,\n",
    "                min_samples_leaf = self.min_samples_leaf,\n",
    "                max_features = self.max_features,\n",
    "                random_state = self.random_state\n",
    "            )\n",
    "            tree.fit(X_train, y_train)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict continuous values for X_test.\"\"\"\n",
    "        predictions = np.array([tree.predict(X_test) for tree in self.trees])\n",
    "        predicted_values = np.mean(predictions, axis=0)\n",
    "        return predicted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "clf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    criterion='squared_error', \n",
    "    max_depth=10,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt', \n",
    "    min_impurity_decrease=0.0,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in y_test before: 1\n",
      "NaN values in y_test after: 0\n",
      "0       4.0\n",
      "1       0.0\n",
      "2       1.0\n",
      "3       5.0\n",
      "4       0.0\n",
      "       ... \n",
      "7620    0.0\n",
      "7621    0.0\n",
      "7622    3.0\n",
      "7623    0.0\n",
      "7624    1.0\n",
      "Name: 280, Length: 7625, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Print the sum of NaN values to confirm their presence\n",
    "print(\"NaN values in y_test before:\", y_test.isna().sum())\n",
    "\n",
    "# Replace NaN with 1\n",
    "y_test.fillna(1, inplace=True)\n",
    "\n",
    "# Verify the replacement\n",
    "print(\"NaN values in y_test after:\", y_test.isna().sum())\n",
    "\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 637.1497870124964\n",
      "RMSE : 25.241826142585175\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5  # Root Mean Squared Error\n",
    "\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(f'RMSE : {rmse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 6.677369345384818\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error (MAE): {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_regressor.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf,'random_forest_regressor.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
