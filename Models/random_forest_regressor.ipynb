{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import  DecisionTreeRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data train\n",
    "file_train='../BlogFeedBack_Dataset/Train/blogData_train.csv'\n",
    "train=pd.read_csv(file_train, header=None)\n",
    "\n",
    "#data test\n",
    "file_test='../BlogFeedBack_Dataset/Train/blogData_train.csv'\n",
    "test=pd.read_csv(file_test, header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((52397, 281), (7625, 281))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_remove = list(range(0, 50)) + list(range(55, 60)) + list(range(276, 280))\n",
    "train = train.drop(train.columns[cols_to_remove], axis=1)  # Drop the first 50 columns\n",
    "test = test.drop(test.columns[cols_to_remove], axis=1)  # Drop the first 50 columns\n",
    "\n",
    "# Split features and labels\n",
    "X_train = train.iloc[:, :-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "X_test = test.iloc[:, :-1]\n",
    "y_test = test.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (52397, 221)\n",
      "y_train shape: (52397,)\n",
      "X_test shape: (7625, 221)\n",
      "y_test shape: (7625,)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes to confirm\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomForestRegressor():\n",
    "    \"\"\"Implement Random Forest regressor from scratch using Decision Tree.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_estimators=100,\n",
    "        criterion='mse', \n",
    "        max_depth=None,\n",
    "        min_samples_leaf=1,\n",
    "        max_features='sqrt', \n",
    "        min_impurity_decrease=0.0,\n",
    "        random_state=0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Some important parameters in Random Forest.\n",
    "        \n",
    "        Args:\n",
    "            n_estimators (int): The number of trees in the forest.\n",
    "            criterion (str): The function to measure the quality of a split ('mse' for mean squared error).\n",
    "            max_depth (int): The maximum depth of the tree.\n",
    "            min_samples_leaf (int): The minimum number of samples required to be at a leaf node.\n",
    "            max_features (str): The number of features to consider when looking for the best split; 'sqrt' for square root.\n",
    "            min_impurity_decrease (float): A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
    "            random_state (int): Controls randomness of the bootstrap samples and the features.\n",
    "        \"\"\"\n",
    "        self.n_estimators = n_estimators\n",
    "        self.criterion =  criterion\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features = max_features\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit the random forest model.\"\"\"\n",
    "        self.n_samples, self.n_features = X.shape\n",
    "        if self.max_features == 'sqrt':\n",
    "            self.max_feature = int(np.sqrt(self.n_features))\n",
    "        \n",
    "        self.trees = []\n",
    "        for i in range(self.n_estimators):\n",
    "            X_train, _, y_train, _ = train_test_split(\n",
    "                X, \n",
    "                y, \n",
    "                test_size=0.3, \n",
    "                random_state=self.random_state + i\n",
    "            )\n",
    "            tree = DecisionTreeRegressor(\n",
    "                criterion = self.criterion,\n",
    "                max_depth = self.max_depth,\n",
    "                min_samples_leaf = self.min_samples_leaf,\n",
    "                max_features = self.max_features,\n",
    "                random_state = self.random_state\n",
    "            )\n",
    "            tree.fit(X_train, y_train)\n",
    "            self.trees.append(tree)\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        \"\"\"Predict continuous values for X_test.\"\"\"\n",
    "        predictions = np.array([tree.predict(X_test) for tree in self.trees])\n",
    "        predicted_values = np.mean(predictions, axis=0)\n",
    "        return predicted_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit model\n",
    "clf = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    criterion='squared_error', \n",
    "    max_depth=32,\n",
    "    min_samples_leaf=4,\n",
    "    max_features='sqrt', \n",
    "    min_impurity_decrease=0.0,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN values in y_test before: 1\n",
      "NaN values in y_test after: 0\n",
      "[17.09765441  0.67844612  5.97938903 ...  2.41585836  3.54634997\n",
      "  0.15260814]\n"
     ]
    }
   ],
   "source": [
    "# Print the sum of NaN values to confirm their presence\n",
    "print(\"NaN values in y_test before:\", y_test.isna().sum())\n",
    "\n",
    "# Replace NaN with 1\n",
    "y_test.fillna(1, inplace=True)\n",
    "\n",
    "# Verify the replacement\n",
    "print(\"NaN values in y_test after:\", y_test.isna().sum())\n",
    "\n",
    "print(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 627.7884973764155\n",
      "RMSE : 25.05570788017005\n",
      "Mean Absolute Error (MAE): 5.702624225119574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse ** 0.5  # Root Mean Squared Error\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(f'RMSE : {rmse}')\n",
    "print(f'Mean Absolute Error (MAE): {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_regressor.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(clf,'random_forest_regressor.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
